{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "356baf69-d19d-4e86-8af1-f6f3ca51b000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\admin\\anaconda3\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\admin\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\admin\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\anaconda3\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79ebe070-158b-48cc-a8ae-27288fd73046",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "\n",
    "# Ensure you have the required NLTK data packages\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42688ee5-7dc1-467f-87be-03270c65a698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nature is the connection between the physical world surrounding us and the life inside us. \n",
      "Nature is God’s most precious and valuable gift to humans. \n",
      "It is the principal source of all essential nutrients for all living things on the planet. \n",
      "‘Nature’ is one of the topics on which we might be asked to write a paragraph. \n",
      "Check the samples provided in the article to learn how to write one on your own\n"
     ]
    }
   ],
   "source": [
    "text=\"\"\"Nature is the connection between the physical world surrounding us and the life inside us. \n",
    "Nature is God’s most precious and valuable gift to humans. \n",
    "It is the principal source of all essential nutrients for all living things on the planet. \n",
    "‘Nature’ is one of the topics on which we might be asked to write a paragraph. \n",
    "Check the samples provided in the article to learn how to write one on your own\"\"\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bef3f87d-908c-4a78-bc29-1eba35bd8c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences: ['Nature is the connection between the physical world surrounding us and the life inside us.', 'Nature is God’s most precious and valuable gift to humans.', 'It is the principal source of all essential nutrients for all living things on the planet.', '‘Nature’ is one of the topics on which we might be asked to write a paragraph.', 'Check the samples provided in the article to learn how to write one on your own']\n",
      "Words: ['Nature', 'is', 'the', 'connection', 'between', 'the', 'physical', 'world', 'surrounding', 'us', 'and', 'the', 'life', 'inside', 'us', '.', 'Nature', 'is', 'God', '’', 's', 'most', 'precious', 'and', 'valuable', 'gift', 'to', 'humans', '.', 'It', 'is', 'the', 'principal', 'source', 'of', 'all', 'essential', 'nutrients', 'for', 'all', 'living', 'things', 'on', 'the', 'planet', '.', '‘', 'Nature', '’', 'is', 'one', 'of', 'the', 'topics', 'on', 'which', 'we', 'might', 'be', 'asked', 'to', 'write', 'a', 'paragraph', '.', 'Check', 'the', 'samples', 'provided', 'in', 'the', 'article', 'to', 'learn', 'how', 'to', 'write', 'one', 'on', 'your', 'own']\n"
     ]
    }
   ],
   "source": [
    "# 1. Break the text into sentences and words\n",
    "sentences = sent_tokenize(text)\n",
    "words = word_tokenize(text)\n",
    "\n",
    "print(\"Sentences:\", sentences)\n",
    "print(\"Words:\", words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31cc4e35-c367-4655-b2b8-bd65a0fda543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Words: ['Nature', 'connection', 'physical', 'world', 'surrounding', 'us', 'life', 'inside', 'us', 'Nature', 'God', 'precious', 'valuable', 'gift', 'humans', 'It', 'principal', 'source', 'essential', 'nutrients', 'living', 'things', 'planet', 'Nature', 'one', 'topics', 'might', 'asked', 'write', 'paragraph', 'Check', 'samples', 'provided', 'article', 'learn', 'write', 'one']\n"
     ]
    }
   ],
   "source": [
    "# 2. Remove common words (stop words)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_words = [word for word in words if word.isalpha() and word not in stop_words]\n",
    "# The general syntax for a list comprehension is: [expression for item in iterable if condition]\n",
    "print(\"Filtered Words:\", filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "310f90ae-d0db-405d-8b0b-854311a44b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed Words: ['natur', 'connect', 'physic', 'world', 'surround', 'us', 'life', 'insid', 'us', 'natur', 'god', 'preciou', 'valuabl', 'gift', 'human', 'it', 'princip', 'sourc', 'essenti', 'nutrient', 'live', 'thing', 'planet', 'natur', 'one', 'topic', 'might', 'ask', 'write', 'paragraph', 'check', 'sampl', 'provid', 'articl', 'learn', 'write', 'one']\n"
     ]
    }
   ],
   "source": [
    "# 3. Reduce words to their base form using stemming\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
    "\n",
    "print(\"Stemmed Words:\", stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d92c2e04-99ea-4611-927a-328017e99415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatized Words: ['Nature', 'connection', 'physical', 'world', 'surrounding', 'u', 'life', 'inside', 'u', 'Nature', 'God', 'precious', 'valuable', 'gift', 'human', 'It', 'principal', 'source', 'essential', 'nutrient', 'living', 'thing', 'planet', 'Nature', 'one', 'topic', 'might', 'asked', 'write', 'paragraph', 'Check', 'sample', 'provided', 'article', 'learn', 'write', 'one']\n"
     ]
    }
   ],
   "source": [
    "# 4. Perform lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
    "\n",
    "print(\"Lemmatized Words:\", lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef57946d-5394-4c4f-aeb5-ac989ade0ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
